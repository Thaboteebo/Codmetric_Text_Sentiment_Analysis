# -*- coding: utf-8 -*-
"""Untitled53.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t6xDxJPBgXZ0TbQLTUaqdsGRfgV_26TK
"""



"""# Task
Analyze product reviews from the dataset "/content/BiodiversityConservationDataset.csv" to determine overall sentiment (positive, neutral, and negative) and uncover customer feedback trends. Load the dataset using pandas, preprocess the text (convert to lowercase, remove punctuation, and filter out stopwords using NLTK or TextBlob), use a sentiment analysis library (e.g., TextBlob) to assign sentiment scores and classify each review, visualize the distribution of sentiment categories using a bar chart or pie chart, and summarize the overall sentiment trends in a brief report.

## Load the dataset

### Subtask:
Load the dataset from "/content/BiodiversityConservationDataset.csv" into a pandas DataFrame.

**Reasoning**:
Import pandas and load the data into a DataFrame. Display the head and info to understand the data structure.
"""

import pandas as pd

df = pd.read_csv('/content/BiodiversityConservationDataset.csv')
display(df.head())
display(df.info())

"""## Preprocess the text

### Subtask:
Clean the text data by converting it to lowercase, removing punctuation, and filtering out stopwords using NLTK or TextBlob.

**Reasoning**:
Import necessary NLTK libraries and download resources if needed, then define and apply the preprocessing function to clean the 'sentence' column.
"""

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

try:
    nltk.data.find('tokenizers/punkt')
except nltk.downloader.DownloadError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except nltk.downloader.DownloadError:
    nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = word_tokenize(text)
    cleaned_tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(cleaned_tokens)

df['cleaned_sentence'] = df['sentence'].apply(preprocess_text)
display(df.head())

"""**Reasoning**:
The previous attempt to download NLTK resources failed because `nltk.downloader` does not have a `DownloadError` attribute. The correct exception to catch is `LookupError`. Also, the download calls should be outside the try-except block for finding the resources.


"""

import string
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import nltk

try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')


stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = word_tokenize(text)
    cleaned_tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(cleaned_tokens)

df['cleaned_sentence'] = df['sentence'].apply(preprocess_text)
display(df.head())

"""**Reasoning**:
The error indicates that 'punkt_tab' is also needed for tokenization in this environment. Download 'punkt_tab' and re-run the preprocessing.


"""

try:
    nltk.data.find('tokenizers/punkt_tab')
except LookupError:
    nltk.download('punkt_tab')

stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = word_tokenize(text)
    cleaned_tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(cleaned_tokens)

df['cleaned_sentence'] = df['sentence'].apply(preprocess_text)
display(df.head())

"""## Perform sentiment analysis

### Subtask:
Use a sentiment analysis library (e.g., TextBlob) to assign sentiment scores and classify each review as positive, neutral, or negative.

**Reasoning**:
Apply the sentiment analysis and classification functions to the 'cleaned_sentence' column to create the 'sentiment_score' and 'sentiment_category' columns as per the instructions.
"""

from textblob import TextBlob

def get_sentiment_polarity(text):
    return TextBlob(text).sentiment.polarity

df['sentiment_score'] = df['cleaned_sentence'].apply(get_sentiment_polarity)

def classify_sentiment(score):
    if score > 0:
        return 'positive'
    elif score < 0:
        return 'negative'
    else:
        return 'neutral'

df['sentiment_category'] = df['sentiment_score'].apply(classify_sentiment)
display(df.head())

"""## Visualize sentiment distribution

### Subtask:
Create a bar or pie chart to visualize the distribution of sentiment categories.

**Reasoning**:
Count the occurrences of each sentiment category and create a bar chart to visualize the distribution.
"""

import matplotlib.pyplot as plt
import seaborn as sns

sentiment_counts = df['sentiment_category'].value_counts()

plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)
plt.title('Distribution of Sentiment Categories')
plt.xlabel('Sentiment Category')
plt.ylabel('Number of Sentences')
plt.show()

"""## Summarize sentiment trends

### Subtask:
Write a brief report summarizing the overall sentiment trends observed in the analysis.

**Reasoning**:
Write a brief report summarizing the overall sentiment trends based on the sentiment counts and the bar plot.
"""

report = """
Overall Sentiment Analysis Report:

The sentiment analysis of the provided sentences reveals a predominantly neutral sentiment.
Out of the 20 sentences analyzed, 14 were classified as neutral, 6 as positive, and 0 as negative.
This indicates that the majority of the text expresses factual or objective statements without a strong positive or negative emotional tone.
While there is a notable presence of positive sentiment, negative sentiment is entirely absent in this dataset.
"""
print(report)

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 20 entries with two columns: 'sentence' and 'sentiment'.
*   After preprocessing (lowercase, punctuation removal, stopword filtering), a new column 'cleaned\_sentence' was created.
*   Sentiment analysis using TextBlob resulted in sentiment polarity scores and a 'sentiment\_category' column classifying reviews as positive, neutral, or negative.
*   The distribution of sentiment categories is as follows: 14 sentences are neutral, 6 are positive, and 0 are negative.
*   The sentiment analysis reveals a predominantly neutral sentiment in the dataset, with a significant presence of positive sentiment and a complete absence of negative sentiment.

### Insights or Next Steps

*   The high proportion of neutral sentiment suggests the text might be largely descriptive or factual, requiring further context or domain-specific analysis to extract more nuanced insights.
*   Investigating the content of the positive sentences could provide valuable feedback on specific aspects that are viewed favorably.

"""